*теорвер* - закономерности в случ явлениях
*случ событие* - фаакт который может произойти или не произойти (A)
*вероятность события* - число характеризующее степень объективной возможности появлени событий (P(A))
вероятность(аксиоматический на основе теории множеств)
	множестов всех исходов - каждый элемент - элементарнное событие
	Ω - пространстов элементарных событий
	событие A - некотрое подмножество Ω

*Достоверное* - происходит в каждом опыте
*Невозможное* - не произойдет
*Несовместным* - события которые в одном опыте произойти одновременно не могут

*сумма* двух событий А и B (A+B) - событие которое заключается в том что происходит хотя бы одно из событий (A|B)
*произведение*(пересечение A * B) - событие когда происходят два вместе (A&B)
*потивоположное* к A - событие B (P(a) = P(U B_i)=1-P(A)=1-P(B_i)=1-П(1-P(b_i))) заключается в том, что событе А не происходит
А_k - полная группа если они попарно несовместны и в сумме образуют достоверное событие
Тождества: A + !A = Ω; A*!A=Ø; A+Ω=Ω; A*Ω=A; A*Ø=Ø; A+Ø=A; !(A+B)=!A*!B; !(A*B)=!A+!B; A+!A*B=A+B

Аксиомы теорвер
	пусть каждомау А ставится число - вероятность события P(A)
	1) 0<=P(A)<=1
	2) P(A+B)=P(A)+P(B) - если A и B несовместные (обобщается на любое число событий, если попарно несовместны)
	A_1 A_n - равновозможны, если P(A_1)=P(A_n);
	Если в опыте Ω - представима в виде группы несовместных равновохможных событий, но такие события - случаи, опыт - схема случаев
	w_i - благоприятное событие - если он элемент множества А

Классическое определение P(A)=m/n (1.4) n-число элеметарных равновозможных исходов m- число равновозмоныхх исходов приводящих к появлению события

Геометрическое в некоторую область случайным образом бросется точка Т P(A)=S(A)/S(Ω) - S() -> площадь области

КОМБИНАТОРИКА
*Выборка (n,r)* - множество , состоящее из r элементов из множества X={x_1,..,x_n}
*Упорядоченная выборка* - с порядком следования P(n,r)=n!/(n,r)!; (1.7)
Если несколько раз извлекли - выборка с повторением  P^(n,r)=n^r; (1.6)
Число неупорядоченных выборок С|r,n = n!/(r!(n,r)!); (1.9)
с повоторениями C^|r,n=(n+r-1)/(r!(n,r)!); (1.8)
Число различных разбиение мн-ва из n элементов на k непересекающихся множеств n = r1+..r_k
Pn(r1,..rk)=n!/(r1!r2!..rk!) (1.10);

////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
вероятность суммы двух совместных событий (P(A U B) = P(A) + P(B) - P(A U B))

*несовместимые* события - если появление одного из них исключает возможность появления остальных {1.11}

Событие A называется *независимым* от события B, если возможность наступления события A не зависит от того, произошло событие B или нет.

*Условной вероятностью* события B при наличии A называется величина {1.17} P(B/A) = P(A n B)
Условную вероятность события P(B/A) можно трактовать как вероятность события B , вычисленная при условии, что событие A произошло .

*Вероятность произведения двух событий* равна вероятности одного из них, умноженной на условную вероятность второго при наличии первого (правило умножения вероятностей).{1.18}
*вероятность произведения нескольких событий* равна произведению вероятностей этих событий, причем вероятность каждого последующего события вычисляется при условии, что все предыдущие имели место{1.19}
*вероятность произведения нескольких независимых событий* равна произведению вероятностей этих событий
попарная независимость не гарантирует совокупной независимости

Каждая *гипотеза* осуществляется случайным образом и представляет собой некоторые события, вероятности которых известны {1.21}
*полная вероятность события A* вычисляется как сумма произведений вероятности каждой гипотезы на условную вероятность события при этой гипотезе.

Следствием правила умножения, и формулы полной вероятности является *теорема гипотез или формула Байеса*
	послеопытные вероятности называются *апостериорными*
	позволяет пересчитать вероятности гипотез в свете новой информации, состоящей в том, что опыт дал результат А

Несколько опытов называются *независимыми опытами*, если вероятность исхода опыта не зависит от того, какие исходы имели другие опыты.
Число к0, которому соответствует максимальная биномиальная вероятность   , называется *наивероятнейшим числом* появления события А. При заданных n и p {1.30}
================================
Под *случайной величиной* понимается величина, которая в результате опыта со случайным исходом принимает то или иное значение
Возможные значения случайной величины образуют множество Ξ, которое называется *множеством возможных значений случайной величины*.
*Дискретные* если множество Ξ счетное и конечное
*Недискретная* - Ξ несчетно
*Законом распределения* СВ называется любое правило (таблица, функция), позволяющее находить вероятности всевозможных событий, связанных со случайной величиной.
(То есть, всякое соотношение, устанавливающее связь между возможными значениями СВ и их вероятностями.)
СВ - *подчинена данному закону распределения*

*Ряд распределения* дискретной случайноу величины - называется таблица в котором в порядке возрастания перечислены все значения X и
вероятности этой величины P (вероятность того что в результате опыта СВ примет значение X)

*Многоугольник вероятностей* - графическое отображение ряда распределения дискретной случайной величины

*Функция распределения* - наиболее общая форма пригодная для всех СВ
ФР СВ - X называется вероятность того, что она примет значение меньшее, чем аргумент функции F(x)=P { X < x }
Вероятность того, что случайная величина Х в результате опыта попадет на участок от α до β (включая α) равна приращению функции распределения на этом участке.
функция распределения F(x)любой случайной величины есть неубывающая функция своего аргумента, значения которой заключены между 0 и 1: 0≤F(x)≤1, причем F(-∞)=0, F(+∞)=1.

ФР дискретной СВ - разрывная ступенчатая

СВ - *непрерывная*, если F(x) - непрерывная функция, кусочно-деффиренцируемая
вероятность любого отдельного значения непрерывной случайной величины равна нулю

*Плотность распределения* - (или плотностью вероятности) непрерывной случайной величины X в точке x называется производная ее функции распределения в этой точке и обозначается f (x )
Вероятность попадания случайной величины X на интервал от x до x+dx равна f (x )dx . Эта величина называется *элементом вероятности*
Вероятность попадания случайной величины X на произвольный участок [a , b ] равна сумме элементарных вероятностей на этом участке (интеграл от f(x)dx по a/b)

*числовыe характеристики случайной величины*
	МО - *математическое ожидание* характеризует среднее взвешенное значение случайной величины.
	Физический смысл МО – это среднее значение случайной величины, то значение, которое  может быть использовано вместо конкретного значения, принимаемого случайной величиной  в приблизительных расчетах или оценках.

	*Момент* - Начальный момент -s-го порядка СВ X есть математическое ожидание s-й степени этой случайной величины
	МО - начальный момент 1 порядка
	*Центрированной СВ* - X0=X-m_x
	*Центральным моментом* s-го порядка СВ X есть математическое ожидание s-й степени центрированной случайной величины

	*Дисперсия* случайной величины есть математическое ожидание квадрата соответствующей центрированной случайной величины.
	Она характеризует степень  разброса значений случайной величины относительно ее математического ожидания, т.е. ширину диапазона значений.
	Дисперсия СВ (как дискретной, так и непрерывной) есть неслучайная (постоянная) величина.
	Дисперсия СВ имеет размерность квадрата случайной величины
	*СКО* измеряется в тех же физических единицах, что и СВ, и характеризует ширину диапазона значений СВ.
	*Правило 3s*. Для большинства значений случайной величины  абсолютная величина ее отклонения от математического ожидания не превосходит утроенного среднего квадратического отклонения, другими словами,
	практически все значения СВ находятся в интервале: [m-3s;m+3s]
	*Модой* случайной величины называется ее наиболее вероятное значение, т.е. то значение, для которого вероятность pi (для дискретной СВ) или f(x) (для непрерывных СВ) достигают максимума. Обозначения: Mx, Mo.:
	*«унимодальным»* называется Распределение с одним максимумом  ряда распределения (для ДСВ) или плотности вероятности (НСВ)
	несколько максимумов - *полимодальный*
	если распределение обладает только минимумом - *антимодальное*
	*Медианой* случайной величины X называется такое ее значение, для  ко­торого выполняется условие P{X<Me} = P{X³Me}. Медиана, как  правило,  существует  только  для непрерывных случайных величин:
	квантилью c_p случайной величины Х называется обратная величина (F(c_p)=p)
	Третий *центральный момент* служит для характеристики асимметрии распределения.
		Если распределение симметрично относительно МО (масса распределена равномерно относительно центра тяжести), то все моменты нечетного порядка равны нулю
		Поэтому для характеристик асимметрии выбирают третий центральный момент – он имеет размерность куба случайной величины.
	Четвертый центральный момент служит для характеристики так называемой «крутости», т.е. островершинности или плосковершинности распределения. Это свойство распределения описывается с помощью *эксцесса*
	Коэффициент *вариации* безразмерная величина, характеризует степень разбросанности значений СВ

производящая функция (для дсв)

типовые распределения


*системоой случайных величин* (случайным вектором, многомерной случайной величиной) называется любая упорядоченная совокупность случайных величин Х ={ X 1 , …, X n }.
	*Функцией распределения* (или совместной функцией распределения ) системы случайных величин называется вероятность совместного выполнения неравенств   X 1 < x 1 , …, X n < x n
	системы двух случайных величин представляет собой  некоторую *поверхность распределения*
	*Элемент вероятности* - f(x,y)dxdy с точностью до бесконечно малых величин равен вероятности попадания случайной точки ( X , Y ) в элементарный прямоугольник R примыкающий к точке (x,y), с размерами dx dy
	Одномерные плотности распределения составляющих системы случайных величин называют *маргинальными плотностями распределения*.
	*Условным законом распределения* называется распределение одной случайной величины, найденное при условии, что другая случайная величина приняла определенное значение.
	св независимы, если x1, x2, x3 не зависят от того, какие значения приняли другие остальные СВ

	Особую роль играет центральный момент порядка 1+1 или второй смешанный центральный момент, который называется   *ковариацией* или *корреляционным моментом*
	Свойства корреляции:
		1)k_xy=k_yx
		2)Корреляционный момент двух независимых случайных величин Х и Уравен нулю
		3)Абсолютная величина корреляционного момента двух случайных величин не превышает среднего геометрического их дисперсий
	*Коэффициент корреляции* служит для оценки тесноты линейной связи между Хи Y : чем ближе абсолютная величина коэффициента корреляции к 1, тем связь сильнее, чем ближе к 0, тем слабее.

числовые характеристики систем случайных величин:
	*Вектор математических ожиданий* - характеризующий среднее значение величин
	*Вектор дисперсий* - характеризующий их рассеивание
	*Корреляционная матрица* - попарная корреляция входящих в систему величин, на диагонали которой будут значения дисперсии (K_ii=D=M[x_i^2]
	*матрица коэффициентов корреляции*.составленная коэффициентов корреляции

условыне ч/х ССВ
*Условным математическим ожиданием* компоненты Х называется математическое ожидание СВ Х, вычисленное  при условии, что  СВ Y приняла определенное значение Y=y и обозначается М(Х/ Y)
Условное математическое ожидание СВ Y при заданном X = x : M[ Y / x ]= m y / x называется *регрессией* Y на x
Регрессионный анализ позволяет выявить характер связи между величинами


МС

закон больших чисел - совокупность теорем, определяющих условия стремления средних арифметических значений случайных величин к некоторой константе, при увеличении числа опытов до бесконечности

+1 теорема чебышева+
При достаточно большом числе независимых опытов среднее арифметическое значений случайной величины сходится по вероятности к ее математическому ожиданию
+2 теорема чебышева+

+теорема бернулли+
При неограниченном увеличении числа опытов до n частота события  А сходится по вероятности к его   вероятности р
Пояснения: В теореме речь идет  лишь о вероятности того, что при достаточно большом числе испытаний относительная частота будет как угодно мало отличаться  от постоянной вероятности появления события в каждом испытании.
Теорема  Бернулли объясняет, почему относительная частота при достаточно большом числе испытаний обладает свойством устойчивости и оправдывает статистическое определение вероятности: в качестве статистической вероятности события принимают относительную частоту или число, близкое к ней.

+центральная предельная теорема+
Если X1…Xn-случайные независимые величины имеющие одно т тоже распределение с математическим ожиданием m и дисперсией σ2, то при увеличении n закон распределения суммы СВ неограниченно приближается к нормальному.

Упрощенный вариант – Если СВ есть сумма большого числа независимых СВ, влияние которых на всю сумму мало, то Х имеет закон распределения, близкий к нормальному.

Теорема Муавра-Лапласа устанавливает условия, при которых биномиальную случайную величину можно приближённо рассматривать как нормальную.

+генеральной совокупностью+ понимают все возможные значения параметра, которые могут быть зарегистрированы в ходе неограниченного по времени наблюдения за объектом
+выборка+ ограниченная
значения xi - варианты
н - объем выборки
Совокупность значений, записанных в порядке их возрастания, называют вариационным рядом
ni = ni / n – относительными частотами (сумма = 1)
ряд накопленных частот, называемый кумулятивным рядом

оценка параметров
Различают два вида оценок – точечные и интервальные. Точечными называют такие оценки, которые характеризуются одним числом.
При малых объемах выборки точечные оценки могут значительно отличаться от истинных значений параметров, поэтому их применяют при большом объеме выборки. Интервальные оценки задаются двумя числами, определяющими вероятный диапазон возможного значения параметра.

Качество оценок характеризуется такими свойствами, как состоятельность, несмещенность, эффективность и достаточность.
	+Состоятельность+ характеризует сходимость по вероятности оценки Θ* к истинному значению параметра Θ при неограниченном увеличении объема выборки n. M[O-O*]^2 -> 0
	+Несмещенность+ характеризует отсутствие систематических (в среднем) отклонений оценки от параметра при любом конечном, в том числе и малом, объеме выборки, M[Θ* ] = Θ.
	+Эффективность+ характеризует разброс случайных значений оценки около истинного значения параметра,
	эффективная оценка – это оценка с минимальной дисперсией
	Достаточность характеризует полноту использования информации, содержащейся в выборке

Стандартизация переменной позволяет упростить расчеты, кроме того, в литературе многие справочные статистические таблицы приводятся именно для стандартизованных переменных.
x=uS+m1

Точечная оценка предполагает нахождение единственной числовой величины, которая и принимается за значение параметра.

Задача точечной оценки параметров в типовом варианте постановки состоит в следующем.
	Имеется: выборка наблюдений (x1, x2, …, xn) за случайной величиной Х. Объем выборки n фиксирован.
	Известен вид закона распределения величины Х, например, в форме плотности распределения f(Θ, x), где Θ – неизвестный (в общем случае векторный) параметр распределения. Параметр является неслучайной величиной.
	Требуется найти оценку Θ* параметра Θ закона распределения.
	Ограничения: выборка представительная.

Метод максимального правдоподобия
	Метод основан на исследовании вероятности получения выборки наблюдений (x1, x2, …, xn).
	Функция правдоподобия - совместноя плотность вероятности
	Следует брать в качестве оценки O* праметар O - то значение, которое обращает функцию в максимум
	-построение функции правдоподобия (ее натурального логарифма);
	-дифференцирование функции по искомым параметрам и составление системы уравнений;
	-решение системы уравнений для нахождения оценок;
	-определение второй производной функции, проверку ее знака в точке оптимума первой производной  и формирование выводов.

Метод моментов
	-выбирается столько эмпирических моментов, сколько требуется оценить неизвестных параметров распределения. Желательно применять моменты младших порядков, так как погрешности вычисления оценок резко возрастают с увеличением порядка момента;
	-вычисленные по ЭД оценки моментов приравниваются к теоретическим моментам;
	-параметры распределения определяются через моменты, и составляются уравнения, выражающие зависимость параметров от моментов, в результате получается система уравнений. Решение этой системы дает оценки параметров распределения генеральной совокупности.
	не более 4 параметров

Метод квантилей
	выбирается столько квантилей, сколько требуется оценить параметров;
	неизвестные теоретические квантили, выраженные через параметры распределения, приравниваются к эмпирическим квантилям.
	Решение полученной системы уравнений дает искомые оценки параметров.

	субъективно из-за выбора квантилей

Статистическая гипотеза представляет собой некоторое предположение о законе распределения случайной величины или о параметрах этого закона, формулируемое на основе выборки
Проверка гипотезы основывается на вычислении некоторой случайной величины – критерия, точное или приближенное распределение которого известно
Тем самым все выборочное пространство и соответственно множество значений критерия делятся на два непересекающихся подмножества S0 и S1. Если значение критерия z попадает в область S0, то гипотеза принимается, а если в область S1, – гипотеза отклоняется. Множество S0 называется областью принятия гипотезы или областью допустимых значений, а множество S1 – областью отклонения гипотезы или критической областью.

два рода ошибок
1) отвергается верная гипотеза
2) принимается неверная гипотеза

доверительная вероятность - это вероятность не совершить ошибку первого рода и принять верную гипотезу Н0.
Вероятность отвергнуть ложную гипотезу Н0 называется мощностью критерия.

сущность
Имеется выборка ЭД фиксированного объема, выбран или известен вид закона распределения генеральной совокупности. Необходимо оценить по этой выборке параметры закона, определить степень согласованности ЭД и выбранного закона распределения, в котором параметры заменены их оценками.

хи квадрат
-Построить гистограмму равновероятностным способом.
-По виду гистограммы выдвинуть гипотезу
-Вычислить значение критерия по формуле
-Из таблицы " Хи-квадрат" уровень значимости
-приянть или отклонить

критерий колмогорова
критерий А.Н. Колмогорова характеризует вероятность того, что величина dn не будет превосходить параметр l для любой теоретической функции распределения.
позволяет проверить согласованность распределений по малым выборкам
-вариационный ряд
-график эмп функции F*(x)
-гипотеза
-график функции F0(x)
-определить макс отклонение по модулю между функциями
-вычислить значение критерия лямда
-уровень значииости
-из таблицы вероятностей выбрать крит значение
-сравнить и принять
(объем от 20)

критерий мизеса
средний квадрат отклонений по всем значениям аргумента x

интервальные оценки
Имеется: выборка наблюдений (x1, x2, …, xn) за случайной величиной Х. Объем выборки n фиксирован.
Необходимо с доверительной вероятностью g=1–a  определить интервал который накрывает истинное значение неизвестного скалярного параметра Θ

ДИ для МО

ДИ для дисперсии



----------
Корреляционный и регрессионный анализ
-----
Для двух случаев изначально необходимо осуществить переход к стандартизированной матрице


[Статистическая зависимость] (изменение одних величин влияет на другие с какой-то вероятностью)
	[Функциональная зависимость] (частный случай статистической)
		точное соответствие одной величины другой
	[Корреляционная зависимость] (частный случай статистической)
		характеризует взаимосявзь значений одних св со средним значением других
			причинная зависимость между значениями параметров
			зависимость между следствиями общей причины

			параметры получившие наибольшее распространение (характеризующие взаимосвязь двух св):
				корреляционный момент(коэффициент ковариации) (формула 7.2)
					неудобный
				коэффициент корреляции (формула 7.3)
					в пределах [-1,1]
					характеризует значимость линейной связи между параметрами
						1 - функциональная зависимость
						-1 обратная функциональная зависимость
						0 - не связаны линейным соотношением

				корреляционная матрица
					симметричная, на главное диагонали единица

				для проверки значимости коэф корр требуется, чтобы распределение вариант подчинялось нормальному закону




	[Регрессионная зависимость] (частный случай статистической)
		вариацию имеет только одна переменная, а другая детерменированная;
		(колличественной зависимости показателей качества от знач его параметров и внешней среды)
		задача: поиск функциональной зависимости y = f (x2,x3,...,xm), которая описывает ЭД (регрессионная функция)
		допущения: достаточно наблюдений, эд может содержать помехи, матрица единственная информация

		1)обработка эд (станд матрица + корр матрица)
		2)выбор уравнения y=f(u1,u2..u_p) + error
			характеризует зависимость между вариацией показателя и варицаией факторов
			не рекомендуется включать факторы которые между собой тесно связаны и мало влияют на y
			полниомиальная функция - основной удобный вариант
				полином 1 степени или уравнение линейной регрессии

		3)выч коэфф
		4) проверка адекватности


2)






